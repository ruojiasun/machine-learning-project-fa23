{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Ruojia Sun, parts of the code are written by Prof. Ami Gates\n",
    "\n",
    "# import PyPDF2\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests  ## for getting data from a server GET\n",
    "import re   ## for regular expressions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign directory\n",
    "directory = 'events-by-state'\n",
    "file_list = []\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        file_list.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader = PyPDF2.PdfReader('us-climate-disasters.pdf')\n",
    "cols = [\"Name\",\"Disaster\",\"Begin Date\",\"End Date\",\"Total CPI-Adjusted Cost (Millions of Dollars)\",\"Deaths\",\"State\"]\n",
    "df = pd.DataFrame(columns = cols)\n",
    "\n",
    "for file in file_list:\n",
    "    df_new = pd.read_csv(file,skiprows=1)\n",
    "    state = file.split('-')[3]\n",
    "    df_new['State'] = [state]*len(df_new.index)\n",
    "    for i_row in range(len(df_new.index)):\n",
    "        search = df[df['Name']==df_new.loc[i_row,'Name']]\n",
    "        if not search.empty:\n",
    "            df.loc[search.index[0],'State']+= f\",{state}\"\n",
    "        else:\n",
    "            df.loc[len(df.index)] = df_new.loc[i_row,:]\n",
    "\n",
    "# df = df.drop_duplicates(subset='Name',keep=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'events-with-states', sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_convert = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = {\"Name\": [], \"Year\": [], \"State\": []}\n",
    "# df['Begin Date'] = pd.to_dateonly(df['Begin Date'])\n",
    "# df['End Date'] = pd.to_datetime(df['End Date'])\n",
    "\n",
    "for i_row in range(len(df.index)):\n",
    "    states = df.loc[i_row,\"State\"].split(',')\n",
    "    year = df.loc[i_row,'End Date']//10000\n",
    "    if len(states) <= 3 and ((year > 2009 and year < 2019) or year == 2021):\n",
    "        for state in states:\n",
    "            query_list[\"Name\"].append(df.loc[i_row,'Name']+' before')\n",
    "            query_list[\"Year\"].append(year)\n",
    "            query_list[\"State\"].append(states_convert[state])\n",
    "\n",
    "            query_list[\"Name\"].append(df.loc[i_row,'Name']+ ' after')\n",
    "            query_list[\"Year\"].append(year+1)\n",
    "            query_list[\"State\"].append(states_convert[state])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reader = PyPDF2.PdfReader('us-climate-disasters.pdf')\n",
    "# # cols = [\"Name\",\"Disaster\",\"Begin Date\",\"End Date\",\"Total CPI-Adjusted Cost (Millions of Dollars)\",\"Deaths\",\"State\"]\n",
    "# df = pd.DataFrame(columns = cols)\n",
    "\n",
    "# for file in file_list:\n",
    "#     df_new = pd.read_csv(file,skiprows=1)\n",
    "#     state = file.split('-')[3]\n",
    "#     df_new['State'] = [state]*len(df_new.index)\n",
    "#     df = pd.concat([df, df_new], axis=0)\n",
    "\n",
    "# # df = df.drop_duplicates(subset='Name',keep=False)\n",
    "# df\n",
    "# df.to_csv(f'events-by-state-with-dup.csv', sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state_fips = pd.read_json('state-fips.json')\n",
    "df_state_fips.columns=df_state_fips.iloc[0]\n",
    "df_state_fips.drop([0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_2017 = ['Disaster Name','Year','State','S1903_C03_001E','S1903_C03_002E','S1903_C03_003E','S1903_C03_004E','S1903_C03_005E',\\\n",
    "           'S1903_C03_006E','S1903_C03_007E','S1903_C03_008E','S1903_C03_009E','S1903_C03_010E',\\\n",
    "           'S1903_C03_011E','S1903_C03_012E','S1903_C03_013E','S1903_C03_014E']\n",
    "\n",
    "cols_2016 = ['Disaster Name','Year','State','S1903_C02_001E','S1903_C02_002E','S1903_C02_003E','S1903_C02_004E','S1903_C02_005E',\\\n",
    "           'S1903_C02_006E','S1903_C02_007E','S1903_C02_008E','S1903_C02_009E','S1903_C02_010E',\\\n",
    "           'S1903_C02_012E','S1903_C02_013E','S1903_C02_014E','S1903_C02_015E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "##\n",
    "##  Step 1: Connect to the server\n",
    "##          Send a query\n",
    "##          Collect and clean the \n",
    "##          results\n",
    "####################################\n",
    "\n",
    "####################################################\n",
    "##In the following loop, we will query thenewsapi servers\n",
    "##for all the topic names in the list\n",
    "## We will then build a large csv file \n",
    "## where each article is a row\n",
    "##\n",
    "## From there, we will convert this data\n",
    "## into a labeled dataframe\n",
    "## so we can train and then test our DT\n",
    "## model\n",
    "####################################################\n",
    "\n",
    "####################################################\n",
    "## Build the URL and GET the results\n",
    "## NOTE: At the bottom of this code\n",
    "## commented out, you will find a second\n",
    "## method for doing the following. This is FYI.\n",
    "####################################################\n",
    "\n",
    "## This is the endpoint - the server and \n",
    "## location on the server where your data \n",
    "## will be retrieved from\n",
    "\n",
    "## TEST FIRST!\n",
    "## We are about to build this URL:\n",
    "## https://newsapi.org/v2/everything?apiKey=8f4134f7d0de43b8b49f91e22100f22b&q=bitcoin\n",
    "\n",
    "\n",
    "endpoint_1=\"https://api.census.gov/data/\"\n",
    "endpoint_2=\"/acs/acs1/subject\"\n",
    "api_key='448115dcad7090fc4be722bf0f1406d1c232d4fd'\n",
    "get_value = \"NAME,group(S1903)\"\n",
    "\n",
    "df_census_2016 = pd.DataFrame(columns = cols_2016)\n",
    "df_census_2017 = pd.DataFrame(columns = cols_2017)\n",
    "# print(df_census.columns)\n",
    "\n",
    "for i in range(len(query_list['Name'])):\n",
    "# for i in range(10):\n",
    "        \n",
    "    year = query_list['Year'][i]\n",
    "    print(i)\n",
    "    row = df_state_fips[df_state_fips['NAME']==query_list['State'][i]]\n",
    "    state_code = row.loc[row.index[0],'state']\n",
    "   \n",
    "    ## Dictionary Structure\n",
    "    URLPost = {'get':get_value,\n",
    "                'key':api_key,\n",
    "                'for':f'state:{state_code}'\n",
    "    }\n",
    "\n",
    "\n",
    "    payload_str = \"&\".join(\"%s=%s\" % (k,v) for k,v in URLPost.items())\n",
    "    endpoint = endpoint_1+str(year)+endpoint_2\n",
    "    # 'format=json&key=site:dummy+type:example+group:wheel'\n",
    "    response = requests.get(endpoint, params=payload_str)\n",
    "\n",
    "    # response=requests.get(endpoint, URLPost)\n",
    "    # print(response.request.url)\n",
    "    print(response)\n",
    "    jsontxt = response.json()\n",
    "    # print(jsontxt)\n",
    "    if response.status_code == 200:\n",
    "\n",
    "    ##############################################`######\n",
    "        df_census = df_census_2017\n",
    "        if year < 2017:\n",
    "            df_census = df_census_2016\n",
    "        ## Open the file for append\n",
    "        # MyFILE=open(filename, \"a\") ## \"a\" for append to add stuff\n",
    "        df_census.loc[len(df_census.index)] = 0   \n",
    "        df_census.loc[len(df_census.index)-1,'Disaster Name'] = query_list['Name'][i]     \n",
    "        df_census.loc[len(df_census.index)-1,'Year'] = year\n",
    "        df_census.loc[len(df_census.index)-1,'State'] = query_list['State'][i]\n",
    "        for j,col in enumerate(jsontxt[0]):\n",
    "            if col in df_census.columns:\n",
    "                df_census.loc[len(df_census.index)-1,col] = jsontxt[1][j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_key_2017 = {'S1903_C03_001E':\"Income, All\",\n",
    "                'S1903_C03_002E':\"Income, White\",\n",
    "                'S1903_C03_003E':\"Income, Black\",\n",
    "                'S1903_C03_004E':\"Income, Native\",\n",
    "                'S1903_C03_005E':\"Income, Asian\",\n",
    "                'S1903_C03_006E':\"Income, Pacific Islander\",\n",
    "                'S1903_C03_007E':\"Income, Other\",\n",
    "                'S1903_C03_008E':\"Income, Two\",\n",
    "                'S1903_C03_009E':\"Income, Hispanic\",\n",
    "                'S1903_C03_010E':\"Income, White Alone\",\n",
    "                'S1903_C03_011E':\"Income, 15 to 24\",\n",
    "                'S1903_C03_012E':\"Income, 25 to 44\",\n",
    "                'S1903_C03_013E':\"Income, 45 to 64\",\n",
    "                'S1903_C03_014E':\"Income, 65 over\"}\n",
    "variable_key_2016 = {'S1903_C02_001E':\"Income, All\",\n",
    "                'S1903_C02_002E':\"Income, White\",\n",
    "                'S1903_C02_003E':\"Income, Black\",\n",
    "                'S1903_C02_004E':\"Income, Native\",\n",
    "                'S1903_C02_005E':\"Income, Asian\",\n",
    "                'S1903_C02_006E':\"Income, Pacific Islander\",\n",
    "                'S1903_C02_007E':\"Income, Other\",\n",
    "                'S1903_C02_008E':\"Income, Two\",\n",
    "                'S1903_C02_009E':\"Income, Hispanic\",\n",
    "                'S1903_C02_010E':\"Income, White Alone\",\n",
    "                'S1903_C02_012E':\"Income, 15 to 24\",\n",
    "                'S1903_C02_013E':\"Income, 25 to 44\",\n",
    "                'S1903_C02_014E':\"Income, 45 to 64\",\n",
    "                'S1903_C02_015E':\"Income, 65 over\"}\n",
    "\n",
    "df_census_2016_renamed = df_census_2016.rename(columns=variable_key_2016)\n",
    "df_census_2017_renamed = df_census_2017.rename(columns=variable_key_2017)\n",
    "df_census = pd.concat([df_census_2016_renamed, df_census_2017_renamed], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census.to_csv(f'income-disaster.csv', sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace negative values with \"Income, All\" values\n",
    "\n",
    "# all = df_census['Income, All']\n",
    "df_census.iloc[:,3:] = df_census.iloc[:,3:].astype('float')\n",
    "df_census.iloc[:,3:] = df_census.iloc[:,3:].mask(df_census.iloc[:,3:] < 0)\n",
    "df_census = df_census.fillna(df_census['Income, All'])\n",
    "df_census\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot by state occurrence for creating visualization\n",
    "df_events_state = pd.read_csv(\"events-by-state-with-dup.csv\")\n",
    "df_events_state\n",
    "\n",
    "df_state_num = pd.pivot_table(df_events_state, values='Name', index='State', aggfunc='count')\n",
    "df_state_num = df_state_num.reset_index()\n",
    "df_state_num.to_csv(f'state_num.csv', sep=',', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
